\chapter{Theoretical Framework\label{cha:chapter3}}

\section{Managing Different Anonymization Granularity}
When planning to integrate anonymization techniques into existing systems, there are many things to consider. First one must understand the data flowing through the system.
Does it include personally identifiable information? Is there further sensitive data? What part of it is necessary for system maintenance? Maybe there is additional data collected for statistics.
Bearing this in mind the next thought would what needs to be anonymized. For this privacy agreements with the user must be taken into account. There may be additional government regulations in place like the \ac{CCPA} in the United States of America or the \ac{GDPR} in the European Union. 
The next course of action is deciding on specific masking functions. As was discussed in \ref{sec:anon} there is a plethora to chose from. It is important to note that all forms of anonymization lead to a loss of information. 
While choosing Blurring or Suppression, two methods that replace attributes with a placeholder, for all critical data fields derived in the previous assessment will ensure that all privacy concerns are addressed, it will also diminish all intelligence gained from collecting this data in the first place. It is questionable if not collecting this type of data in the first place would then be the better solution as it would save storage and computing power. 
An alternative approach would be to invest heavily in the IT security ensuring that no intruder with malicious intent can gain access to sensitive data. Keeping in mind, however, that social engineering attacks are nowadays the most common and effective strategy (SAUCE) giving a guarantee of safety can be impossible. It also stands to reason that the more employees a company has the risk for social
engineering attacks increases. Both of these radical approaches do not seem to adequately solve the problem. Fortunately, there is a way to navigate between these two extremes. An attentive observer of the company's data operations will likely notice that data can and should be restricted similarily to permissions: Only the data needed to furfill the user's duty should be accessible to the user. 
In addition, there are anonymization techniques, which do not lead to total information loss like the two mentioned before. Generalization for example can be employed to significantly reduce the re-identification of individuals, while simultaneously retaining some information.
With data restriction and different anonymization techniques in mind there is a middle ground to be found which maximizes security and minimizes information loss. Consider the following example:

\subsection{Use Case Example}
Hospitals depend on the collection, management and analysis of data to administer the best and most accurate care of their patients. In a modern hospital all data would be stored in a centralized hospital database. 
Here all data for individual patients are brought together. Table \ref{table:dia_patient} shows an exemplary entry of a patient in the diabetes and endocrinology ward of a german hospital. Note that the table has been shortened to enhance its clarity and readability.  (A MORE DETAILED VERSION CAN BE FOUND IN THE APPENDIX)


\bigskip 


\begin{table}[ht]
    \begin{center}
    \footnotesize{
        \renewcommand{\arraystretch}{1.5}
        \begin{tabular}{ | c | c | c | c | c | c | c | c | c | c | c | } 
            \hline
            pid & name & addr. & gender & age & ins. co. & ins. no. & diag. & gluc. & hba1c & med. \\
            \hline
            1 & F. Ott & Berlin & M & 28 & TK & K15489 & E10 & 22.1 & 8.74 & Insulin \\
            \hline
        \end{tabular}
    }
    \caption{Example datum of a diabetes patient}
    \label{table:dia_patient}
    \end{center}
\end{table}

The header of table \ref{table:dia_patient} shows eleven attributes. First the person id (\textit{pid}), which is the primary key for each patient as it uniquely identifies the patient in the database. Then \textit{name}, address (\textit{addr.}), \textit{gender} and \textit{age} are included as additional personal information.
This would typically also include the full address not just the city name, contact information, height as well as weight to adapt the dosage of the medication. The subsequent two attributes include information about the patient's insurance information. 
Insurance companies in Germany are uniquely identified with a nine digit institutional identifier. In this example the insurance company (\textit{ins. co.}) has the value 101575519, which matches the identifier of the Techniker Krankenkasse (TK). 
Each client is then assigned a number unique to that insurance company called the insurance number (\textit{ins. no.}). It always starts with a letter followed by digits. Finally, the datum references the medical information. It starts with the diagnosis (\textit{diag.}) classified according to the \ac*{ICD}. 
E10 being the label for Type 1 Diabetes Mellitus. The most important medical measurement for the treatment of this disease is the current amount of glucose (\textit{gluc.}) in the blood. This determines the quantity of medication (\textit{med.}) to be administered to the patient. For Type 1 Diabetes this is Insulin. 
Lastly, the table includes an attribute called \textit{hba1c}. This is the body's own three-month average of blood glucose. By means of which diabetes is diagnosed. In this case it is also symbolic for all additional diagnostic findings. 
Glucose and HbA1c are intentionally distinguished as separate attributes in this dataset, despite both being blood-derived metrics, due to their distinct measurement methodologies and relevance in immediate treatment contexts. Glucose can be ascertained with a single drop of blood, providing critical information for the immediate treatment.
Conversely, HbA1c is derived from a complete blood count and does not require instant action. \newline

In a hospital setting, numerous actors engage with the aforementioned dataset. The most straightforward and prominent is the doctor. She will need all data to fulfill her duties. The doctor's letter contains all personal information. The medical data is needed for diagnosis and treatment. 
She will also need to keep the insurance information in mind as the covered treatment options are oftentimes different for each company. Additionally, she will need to write the patient's insurance information on the rescriptions. Only the pid could be omitted, but is debatable if the overhead is worth it, considering the pid can be easily inferred with all the given information.
Therefore, no anonymization to the doctor's data makes the most sense. \\
Supporting the doctor is the nurse staff. One of their main tasks is to monitor patients and administer medication. To accomplish this they require the diagnosis, medication and in this case the glucose data. As the HbA1c value is not relevant for the immediate treatment it can be safely ommitted. 
Again insurance information is necessary as nurses typically do have the liberty of administer medication according to their own judgement. This is especially important when considering how understaffed hospitals in Germany are most of the time. On the other hand the patient's personal insurance number does not play into this. As nurses also interact directly with the patients they need some basic personal information like name and gender. 
Pid and address, however, are not required. Therefore, the data for the nurse staff can be anonymized as shown in Table \ref{table:nurse} without limiting the nurses or losing valuable information. 

\bigskip

\begin{table}[ht]
    \begin{center}
    \footnotesize{
        \renewcommand{\arraystretch}{1.5}
        \begin{tabular}{ | c | c | c | c | c | c | c | c | c | c | c | } 
            \hline
            pid & name & addr. & gender & age & ins. co. & ins. no. & diag. & gluc. & hba1c & med. \\
            \hline
            * & F. Ott & * & M & 28 & TK & * & E10 & 22.1 & * & Insulin \\
            \hline
        \end{tabular}
    }
    \caption{Data available for the nurse staff. Note that pid, address, insurance number and additional medical information.}
    \label{table:nurse}
    \end{center}
\end{table}

In tandem with the stay and medical treatment of the patient, the administartion of the hospital will want to collect the money from the patient's insurance. The insurance company together with the patient's personal insurance number will suffice as identification. 
Administered medication will be imperative as this dictates the amount of money the hospital will get in addition to the fees for the stay. For this the diagnosis will typically have to be added as a suitable reason. No further information is required. Limiting the amount of data here 
is crucial as here the data is exported to a third party. Which means that additional regulations will take effect. Minimizing the data leaving the hospital minimizes security risks. With these strict rules in place the data can be adjusted as seen in Table \ref{table:administration}. \newline 
Note at this point that an attacker, who has gained access to both the data of the nurse staff and that of the administration, would struggle to correlate the entries. The shared available data fields insurance company, diagnosis and medication are likely generic enough to not point to a singular but to many patients. 

\bigskip

\begin{table}[ht]
    \begin{center}
    \footnotesize{
        \renewcommand{\arraystretch}{1.5}
        \begin{tabular}{ | c | c | c | c | c | c | c | c | c | c | c | } 
            \hline
            pid & name & addr. & gender & age & ins. co. & ins. no. & diag. & gluc. & hba1c & med. \\
            \hline
            * & * & * & * & * & TK & K15489 & E10 & * & * & Insulin \\
            \hline
        \end{tabular}
    }
    \caption{Data available for the administration. Note that only the insurance information, medication and diagnosis are not suppressed.}
    \label{table:administration}
    \end{center}
\end{table}

Diabetes, which afflicts over ten percent of the global population and demonstrates a rising prevalence, stands as one of the most common chronic diseases worldwide \cite{idf2023,WHODiabetes2023}. Given its mostly non-lethal progression and lifetime dependency on medication, 
it has given rise to a substatial market. As cause, optimal treatment and cure remain subject to research, data of especially newer diabetes patients is in hot demand. To provide this data to research institutes in accordance with the regulations in place the hospital must ensure that no concrete patient can be reidentified. 
Here, advanced anonymization techniques such as K-Anonymization come into place. Each attribute of the data entry can be assigned to one of three categories: personally identifiable, quasi indentifying and remaining attributes. To achieve k anonymity each entry must supress the personally identifiable attributes, while keeping the remaining attributes untouched. 
Most importantly the quasi identifiable attributes of each data entry must be the same for at least k - 1 other entries of a data set. This is typically achieving with generalization of these attributes until k entries are found. In this use case the personally identifiable attributes are \textit{pid}, \textit{name}, \textit{address} and \textit{insurance number}. 
The quasi indentifying attributes are \textit{gender}, \textit{age} and \textit{insurance company}. The medical data comprive the remaining attributes. A K anonymous version of this data extry is depicted in Table \ref{table:k_anon}.

\bigskip

\begin{table}[ht]
    \begin{center}
    \footnotesize{
        \renewcommand{\arraystretch}{1.5}
        \begin{tabular}{ | c | c | c | c | c | c | c | c | c | c | c | } 
            \hline
            pid & name & addr. & gender & age & ins. co. & ins. no. & diag. & gluc. & hba1c & med. \\
            \hline
            * & * & * & \{M, F, X\} & {[20 - 30]} & ins. co. & * & E10 & 22.1 & 8.74 & Insulin \\
            \hline
        \end{tabular}
    }
    \caption{Data available for external research. Note the untouched medical, the suppressed personally identifying and generalized quasi identifiable attributes.}
    \label{table:k_anon}
    \end{center}
\end{table}

While the aforementioned diabetes patient use case scenario may appear unique and specific, the aspects and nuances are applicable in numerous contexts. The distinct data requirements for doctors, nurses, administration and research are anticipated to persist, albeit adapted, throughout the entire healthcare industry. 
It is also viable in different sectors. Imagine security levels in government matters, trade secrets and specific customer knowledge in corporations or secrecy of correspondense for the transportation industry. Distributed event stores are utilized across all of these sectors with major players relying on Apache Kafka for their day to day needs \cite{KafkaPoweredBY}. 

\section{Masking Functions}
Data anonymization is a multifaceted process tailored to meet application requirements, user groups and their specific needs. This section goes in depth into masking functions, the cornerstone of data anonymization. In this context a \textit{datum} refers to a single piece of information e.g. a singular entry of a database or any one event of a data stream. Synonymous with it also used the word \textit{tuple}. A tuple is comprived of one or multiple \textit{attributes} (also called \textit{fields}). It is customary for individual tuples to be part of a bigger collection. In the static context they are collected in databases and grouped in tables. Data streams work analogous for dynamic operations. All tuples of the same database table or data stream are required to follow the same pattern. This refers to the sequence of attributes of each tuple. This pattern is fixed in a data schema associated with the table or stream. Sometimes it is appended to each datum in form of a header as seen exemplary in Table \ref{table:dia_patient}. As this substantially increases the size of each datum it is more common to define it once in the initialization step of the database table or data stream. \\
While all forms of anonymization aim to alter the underlying sensitive information, e.g. the tuple's attributes containing perhaps personally identifiying information, in a way that makes it harder if not impossible to reconstruct, they can be categorized based on their scope of operation:

\begin{itemize}
    \item \textbf{Value-Based} Handles one tuple at a time and replaces the values of attributes independently. 
    \item \textbf{Tuple-Based} Operates on individual attributes of a single tuple, but considers the values of the entire tuple for the change. 
    \item \textbf{Attribute-Based} Extends the view from one tuple to a larger collection or table of data. Evaluates the values of singular attributes of the entire set and collectively makes changes to that attribute accordingly. 
    \item \textbf{Table-Based} Covers a table of data and perceives all attributes of each tuple. Adaptions to multiple attributes simultaneously are common. It can be argued that methods falling under this category are not masking functions but algorithms utilizing many masking functions to achieve anonymization on a table level.  
\end{itemize}

To better illuminate the relationship and hierarchy of the aforementioned categories as well as provide some examples, refer to Figure \ref{fig:hierarchy_mf}. 

\begin{figure}[ht]
    \begin{tikzpicture}[node distance=1.5cm, auto, trim left=-2.5cm]
        % Define block styles
        \tikzstyle{box} = [rectangle, draw, rounded corners, fill=blue!20, text width=5em, text centered, minimum height=3em]
        \tikzstyle{line} = [draw, -latex']

        % Nodes
        
        \node [box, text width=5em, xshift=-1cm] (value) {Value Based};
        \node [box, right=of value, text width=5em] (tuple) {Tuple Based};
        \node [box, right=of tuple, text width=6em] (attribute) {Attribute Based};
        \node [box, right=of attribute, text width=5em] (table) {Table Based};
        \node [box, fill=purple!30, above=of tuple, text width=9em] at ($(value)!0.5!(tuple)$) (semantics1) {Tuple-at-the-time\\ Semantics};
        \node [box, fill=purple!30, above=of attribute, text width=6em] at ($(attribute)$) (semantics2) {Table Semantics};
        \node [box, fill=purple!50, above=of semantics1, text width=6em] at ($(semantics1)!0.5!(semantics2)$) (masking) {Masking Functions};
        \node [box, fill=white, text width=6em, opacity=0, above=of table] at ($(table)$) (reference){};
        \node [box, fill=green!30, above=of reference, text width=7.5em] at ($(reference)$) (anonymizations) {Table Anonymizations};


        % Lists
        \node[below=0.2cm of value] (value_mf) {
            \begin{tabular}{l}
                - Suppression \\
                - Blurring \\
                - Substitution \\
                - Tokenization \\
                - Generalization \\
                - Bucketizing \\
                - Noise Methods
            \end{tabular}
        };

        \node[below=0.2cm of tuple] (tuple_mf) {
            \begin{tabular}{l}
                - Conditional \\ Substitution
            \end{tabular}
        };

        \node[below=0.2cm of attribute] (attribute_mf) {
            \begin{tabular}{l}
                - Shuffling \\
                - Averaging \\
                - Aggregation \\
                - Univariate \\ Microaggregation
            \end{tabular}
        };

        \node[below=0.2cm of table] (table_mf) {
            \begin{tabular}{l}
                - Multivariate \\ Microaggregation \\
                - k-anonymization \\
                - l-diversity \\
                - t-closeness \\
                - eps-privacy
            \end{tabular}
        };

        % Paths
        \path [line] (masking) -- (semantics1);
        \path [line] (masking) -- (semantics2);
        \path [line] (semantics1) -- (value);
        \path [line] (semantics1) -- (tuple);
        \path [line] (semantics2) -- (attribute);
        \path [line] (anonymizations) -- (table);

    \end{tikzpicture}
    \caption{Hierarchy of masking functions}\label{fig:hierarchy_mf} 
\end{figure}

Having outlined the structure and dimensions of the various masking functions, it is now time to take a closer look at the functionality and use cases of the examples given in Figure \ref{fig:hierarchy_mf} starting with the value based. \\
\textbf{Suppression} aims to effectively delete the value by replacing the value of an attribute with a meaningless character, most commonly the asterisk \textit{*}. It is important to note, that actually removing the attribute from the tuple or replacing it will a null value would violate the data schema and thus negatively impact operability. The asterisk does the trick while maintaining the data schema. To work Suppression only requires a non-empty set of keys for the attributes that are supposed to be suppressed as parameter. Naturally, it leads to total information loss of the specfified fields. This can be particular useful for containing personally identifiable data like a person's home address as exemplary shown in Figure \ref{fig:suppression}. 

\bigskip

\begin{figure}[ht]
    \begin{center}
    \footnotesize{
        \renewcommand{\arraystretch}{1.5}
        \begin{tabular}{|c|}
            \hline
            address \\
            \hline
            Smith Street 3 \\
            \hline
            \end{tabular}
            \quad $\longrightarrow$ \quad
            \begin{tabular}{|c|}
            \hline
            address \\
            \hline
            * \\
            \hline
        \end{tabular}
    }
    \end{center}
    \caption{Example of suppression of an attribute.\label{fig:suppression}}
\end{figure}

A similar approach is applied in \textbf{Blurring}. Here the value of an attribute is replaced with arbitrary characters, typically \textit{X}s. It is distinguishable from Suppression in that not all characters of the value have to be replaced and even the amount of characters can remain the same. Imagine a user at the checkout of an online store that they have already purchased goods at prior to this session. Here the credit card information of that user was saved as part of the agreement from the previous session. The user is then given the option to use that credit card again, with it being specified as a sequence of blurred characters with only the last three digits in plain text as shown in Figure \ref{fig:blurring}. This allows the user to double-check the card information without exposing the credit card number to the network, screen capturers or bystanders. This operation also leads to high information loss but retains some usability of the value. The parameters for Blurring include the keys to blurr as well as optionally the number of characters and whether the amount of characters is to be maintained. Note, that setting the parameters to blur all characters and reduce the amount to one is equal in funtionality to Suppression. 

\bigskip

\begin{figure}[ht]
    \begin{center}
    \footnotesize{
        \renewcommand{\arraystretch}{1.5}
        \begin{tabular}{|c|}
            \hline
            credit card \\
            \hline
            1234 5678 9123 4567 \\
            \hline
            \end{tabular}
            \quad $\longrightarrow$ \quad
            \begin{tabular}{|c|}
            \hline
            credit card \\
            \hline
            XXXX XXXX XXXX X567 \\
            \hline
        \end{tabular}
    }
    \end{center}
    \caption{Example of blurring of an attribute.\label{fig:blurring}}
\end{figure}

\textbf{Substitution} replaces the value of the specified attribute with a predefined substitute. Figure \ref{fig:substitution} shows an example where a name is switched out with an arbitrary fake name from a library. While this masking function leads to substantial information loss, it seemingly maintains the integrity of the data from an outsider's perspective. This can make the data easier to work with, while still ensuring anonymity. As parameters the keys for the attributes that are supposed to be substituted are required in tandem with the intended substitutes. 

\bigskip

\begin{figure}[ht]
    \begin{center}
    \footnotesize{
        \renewcommand{\arraystretch}{1.5}
        \begin{tabular}{|c|}
            \hline
            name \\
            \hline
            Henri Allgöwer \\
            \hline
            \end{tabular}
            \quad $\longrightarrow$ \quad
            \begin{tabular}{|c|}
            \hline
            name \\
            \hline
            John Doe \\
            \hline
        \end{tabular}
    }
    \end{center}
    \caption{Example of substitution of an attribute.\label{fig:substitution}}
\end{figure}

An alternative approach is \textbf{Tokenization}. Here values are also substituted, but not with some arbitrary replacement. Instead, the substitute is a specific token. These tokens can be reversed to restore the original value as long as a secret is known with which the token was created. There are different approaches to achieve this. The first one coming to mind is a database mapping token to the hash of the original value. Only access to the database as well as the hashing function will yield the correct original value from the token. Another approach is to omit the database and instead use a more sophisticated cryptographic algorithm to create the token, essentially encrypting the data. While this masking function manages to preserve the information, it requires substantial overhead in form of storage for the database and/or computing power for the cryptographic algorithms. This costly masking function is usually reserved for highly sensitive data. For instance passwords as illustrated in Figure \ref{fig:tokenization}.

\bigskip

\begin{figure}[ht]
    \begin{center}
    \footnotesize{
        \renewcommand{\arraystretch}{1.5}
        \begin{tabular}{|c|}
            \hline
            password \\
            \hline
            MyPassword1 \\
            \hline
            \end{tabular}
            \quad $\longrightarrow$ \quad
            \begin{tabular}{|c|}
            \hline
            password \\
            \hline
            d9f4c3b72c7935e5 \\
            \hline
        \end{tabular}
    }
    \end{center}
    \caption{Example of tokenization of an attribute.\label{fig:tokenization}}
\end{figure}

One of the most common masking functions is \textbf{Generalization}. Here, the value of an attribute is abstracted to a more general value. This effectively reduces the information, but does not remove it entirely. For example a datum with an address field could generalize the exact location to a broader one. Instead of Berlin it would read Germany as shown in Figure \ref{fig:generalization}. This could then be even further generalized to Europe and so forth. Typically, entire generalization hierarchies are provided as parameter to facilitate this. It is crucial that these hierarchies are exhaustive of all possible arising values if no default is provided as genarlization is ambiguous. These complete generalization hierarchies are required as parameters in addition to their respective attribute key. 

\bigskip

\begin{figure}[ht]
    \begin{center}
    \footnotesize{
        \renewcommand{\arraystretch}{1.5}
        \begin{tabular}{|c|}
            \hline
            address \\
            \hline
            Berlin \\
            \hline
            \end{tabular}
            \quad $\longrightarrow$ \quad
            \begin{tabular}{|c|}
            \hline
            address \\
            \hline
            Germany \\
            \hline
        \end{tabular}
    }
    \end{center}
    \caption{Example of the generalization of an attribute.\label{fig:generalization}}
\end{figure}

A special case of Generalization is \textbf{Bucketizing}. It functions similarly, but exclusively for numerical values. Ranges replace specific values in the tuple. Figure \ref{fig:bucketizing} shows an example where the age 27 is bucketized to the range {[20 - 30]}. Only a moderate amount of information is lost with this masking function. To deploy it requires the bucket sizes as well as the keys to the numerical attribute. 

\bigskip

\begin{figure}[ht]
    \begin{center}
    \footnotesize{
        \renewcommand{\arraystretch}{1.5}
        \begin{tabular}{|c|}
            \hline
            age \\
            \hline
            27 \\
            \hline
            \end{tabular}
            \quad $\longrightarrow$ \quad
            \begin{tabular}{|c|}
            \hline
            age \\
            \hline
            {[20 - 30]} \\
            \hline
        \end{tabular}
    }
    \end{center}
    \caption{Example of bucketizing of an attribute.\label{fig:bucketizing}}
\end{figure}

Finally, there are the \textbf{Noise Methods}. Again, these only apply to numerical data. The idea is to modify the original values by adding noise. Typically, this noise is chosen randomly from a distribution. Utilizing the normal distribution with mean 0 it would ensure that the data over a period of time would retain its average and distribution. The standard deviation will then define how much each individual data point can diverge from the original value. The result will invalidate individual tuples but preserve the overall spread of the data in the long run. As an example Figure \ref{fig:noise} shows noise added to two attributes of a tuple. Note that with no loss to the generality one is decreased, while the other increased. 

\bigskip

\begin{figure}[ht]
    \begin{center}
    \footnotesize{
        \renewcommand{\arraystretch}{1.5}
        \begin{tabular}{|c|c|}
            \hline
            height & weight \\
            \hline
            185 & 83 \\
            \hline
            \end{tabular}
            \quad $\longrightarrow$ \quad
            \begin{tabular}{|c|c|}
            \hline
            height & weight  \\
            \hline
            181 & 84\\
            \hline
        \end{tabular}
    }
    \end{center}
    \caption{Example of adding noise.\label{fig:noise}}
\end{figure}

\section{System Requirements}
\subsection{Data Stream Integration}
\subsection{Administration}
\subsection{Performance}
\subsection{Adaptability}
\subsection{Scalability}
\subsection{Reliability}



%%\lstset{frame=tb,framerule=1pt,keywordstyle=\color{blue}}
%%\begin{comment} 
%%\begin{lstlisting}[ language=SQL,caption= An Example Code Fragment]
%%SELECT 
%%    attribute 
%%FROM 
%%    table
%%WHERE 
%%    attribute = 'value';
%%    
%%\end{lstlisting}
%%\end{comment} 
%%\begin{lstlisting}[ language=Emma,caption= Bounce rate program using nested bags and nested parallel operations\cite{Parallelism}.]
%%val visits: Bag[(Date, IP)] = readFile(...)
%%val visitsPerDay: Bag[(Date, Bag[IP])] = 
%%    visits.groupByKey()
%%visitsPerDay.map{
%%    (day: Date, group: Bag[IP]) =>
%%val countsPerIP = group.map((_, 1)).reduceByKey(_+_)
%%val numBounces = countsPerIP.filter(_._2 == 1).count()
%%val numTotalVisitors = group.distinct().count()
%%val bounceRate =
%%numBounces / numTotalVisitors
%%return bounceRate
%%}

    
%%\end{lstlisting}